# -*- coding: utf-8 -*-
"""Ch7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ySuqFdf-Onpqg_Gw1_TaNPtq0fGkJlVm
"""

!pip install pytesseract

!cat /etc/os-release

!sudo apt install tesseract-ocr

"""# Using PIL"""

import pytesseract
from PIL import Image

im = Image.open("./image1.jpg").convert('L')
txt = pytesseract.image_to_string(im)

print(txt)

"""# Using OpenCV"""

import cv2
import numpy as np

im = cv2.imread('image2.jpg')
im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)

txt = pytesseract.image_to_string(im)
print(txt)

import cv2
import numpy as np

im = cv2.imread('image2.jpg')
im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)

txt = pytesseract.image_to_string(im)
print(txt)

im = cv2.imread('image2.jpg')
im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
boxes = pytesseract.image_to_boxes(im) 

image_height = im.shape[0]

for box in boxes.splitlines():
    p = box.split()
    boxed_img = cv2.rectangle(im, (int(p[1]), image_height - int(p[2])), 
                        (int(p[3]), image_height - int(p[4])), (0, 255, 0), 2)

Image.fromarray(boxed_img)

im = cv2.imread('image2.jpg')
im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)

print(pytesseract.image_to_data(im))

"""# TensorFlow

"""

from google.colab import drive
drive.mount('/content/gdrive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/gdrive/MyDrive/data/

!unzip "A_Z Handwritten Data.csv.zip"

import tensorflow as tf
from tensorflow.keras.datasets import mnist
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
import matplotlib.pyplot as plt

file = open("A_Z Handwritten Data.csv")
az_images = list() # to store A-Z image data (pixel values)
az_labels = list() # to store A-Z image labels

for line in file:
    values = line.split(",")
    az_labels.append(values[0])
    image_data = np.array([int(i) for i in values[1:]]).reshape((28, 28))
    az_images.append(image_data)

(digit_train_images, digit_train_labels), (digit_test_images, digit_test_labels) = mnist.load_data()
digit_train_labels = digit_train_labels.astype("str")
digit_test_labels = digit_test_labels.astype("str")

actual_labels = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
az_labels_actual = np.array([actual_labels[int(i)] for i in az_labels])

az_images = np.array(az_images)
az_images.shape

i = 1
for num in np.random.randint(0, 372451, [6,]):
    ax = plt.subplot(2, 3, i)
    ax.set_title("Alphabet: {0}".format(az_labels_actual[num]))
    ax.imshow(az_images[num], cmap='gray')
    i+=1

az_train_images, az_test_images, az_train_labels, az_test_labels = train_test_split(az_images,
                                                                                    az_labels_actual,
                                                                                    random_state=123, 
                                                                                    test_size=0.25, 
                                                                                    shuffle=True)

az_labels_actual.shape

del az_images
del az_labels_actual

training_data = np.vstack([az_train_images, digit_train_images])
training_labels = np.hstack([az_train_labels, digit_train_labels])

test_data = np.vstack([az_test_images, digit_test_images])
test_labels = np.hstack([az_test_labels, digit_test_labels])

del az_train_images 
del az_train_labels
del digit_train_images
del digit_train_labels

del az_test_images
del az_test_labels
del digit_test_images
del digit_test_labels

training_data = training_data/255
test_data = test_data/255

le = LabelBinarizer()
training_labels = le.fit_transform(training_labels)
test_labels = le.transform(test_labels)

def create_model():
    inputs = tf.keras.layers.Input(shape=(28,28,1))
    x = tf.keras.layers.Conv2D(filters=32, kernel_size=(5, 5))(inputs)
    x = tf.keras.layers.Activation("relu")(x)
    x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)
    x = tf.keras.layers.Dropout(0.3)(x)

    x = tf.keras.layers.Conv2D(filters=64, kernel_size=(5, 5))(inputs)
    x = tf.keras.layers.Activation("relu")(x)
    x = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(x)
    x = tf.keras.layers.Dropout(0.3)(x)

    x = tf.keras.layers.Flatten()(x)
    x = tf.keras.layers.Dense(128, activation='relu')(x)
    x = tf.keras.layers.Dense(128, activation='relu')(x)
    predictions = tf.keras.layers.Dense(len(le.classes_), activation='softmax')(x)

    model = tf.keras.models.Model(inputs=inputs, outputs=predictions)
    return model

model = create_model()
model.summary()

model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss=tf.keras.losses.CategoricalCrossentropy(),
    metrics=[tf.keras.metrics.CategoricalAccuracy()],
)

history = model.fit(training_data, training_labels, 
                    validation_data=(test_data, test_labels), 
                    epochs=20, batch_size=128, verbose=2)

# plot accuracy
plt.plot(history.history['categorical_accuracy'])
plt.plot(history.history['val_categorical_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()
# plot loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

model.evaluate(test_data, test_labels)

"""# Transformer"""

!pip install transformers

from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import requests
from PIL import Image

processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-handwritten")

image = Image.open("gm.png").convert("RGB")

pixel_values = processor(image, return_tensors="pt").pixel_values

generated_ids = model.generate(pixel_values)

generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
print(generated_text)

generated_ids

