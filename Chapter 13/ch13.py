# -*- coding: utf-8 -*-
"""Ch13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XFZkCgO3jdOi5lsAoG-vJV4NU0XUWLo0
"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()

del train_labels, test_images, test_labels

print(train_images.shape)

train_images = np.expand_dims(train_images, -1).astype('float32')
print(train_images.shape)

train_images = (train_images - 127.5) / 127.5

BUFFER_SIZE = 60000
BATCH_SIZE = 128
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(1)

def create_generator():
    inputs = tf.keras.Input(shape=(100,))
    x = tf.keras.layers.Dense(7*7*256, use_bias=False)(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.ReLU()(x)
    x = tf.keras.layers.Reshape((7, 7, 256))(x)

    #block 1
    x = tf.keras.layers.Conv2DTranspose(128, kernel_size=(5, 5), strides=(1, 1), padding='same', use_bias=False)(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.ReLU()(x)

    #block 2
    x = tf.keras.layers.Conv2DTranspose(64, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False)(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.ReLU()(x)

    #block 3
    outputs = tf.keras.layers.Conv2DTranspose(1, kernel_size=(5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')(x)
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

def generate_noise(batch_size, noise_dimension):
    noise = tf.random.normal([batch_size, noise_dimension])
    return noise

generate_noise(1, 10)

generator = create_generator()

noise = generate_noise(1, 100)
generated_image = generator(noise, training=False)

plt.imshow(generated_image[0], cmap='gray')

def create_discriminator():
    inputs = tf.keras.Input(shape=(28,28,1))
    x = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')(inputs)
    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)
    x = tf.keras.layers.Dropout(0.4)(x)

    x = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')(x)
    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)
    x = tf.keras.layers.Dropout(0.4)(x)

    x = tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same')(x)
    x = tf.keras.layers.LeakyReLU(alpha=0.2)(x)
    x = tf.keras.layers.Dropout(0.4)(x)

    x = tf.keras.layers.Flatten()(x)
    outputs = tf.keras.layers.Dense(1)(x)
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

discriminator = create_discriminator()
prediction = discriminator(generated_image)
print(prediction)

def bce_loss(y_true, y_pred):
    loss_func = tf.keras.losses.BinaryCrossentropy(from_logits=True)
    return loss_func(y_true, y_pred)

generator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)
discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=2e-4, beta_1=0.5)

EPOCHS = 50
noise_dimension = 100
num_images_to_generate = 20

seed = generate_noise(num_images_to_generate, noise_dimension)

for epoch in range(EPOCHS):
    print(epoch)
    for real_image_batch in train_dataset:
        noise = tf.random.normal([BATCH_SIZE, noise_dimension])

        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
            generated_images = generator(noise, training=True)

            real_preds = discriminator(real_image_batch, training=True)
            fake_preds = discriminator(generated_images, training=True)

            real_and_fake_preds = tf.concat([real_preds, fake_preds], axis = 0)

            y_true = tf.constant([[1.]] * len(fake_preds))
            generator_loss = bce_loss(y_true, fake_preds)

            y_true = tf.constant([[1.]] * len(real_preds) + [[0.]] * len(fake_preds))
            discriminator_loss = bce_loss(y_true, real_and_fake_preds)

        gradients_generator = gen_tape.gradient(generator_loss, generator.trainable_variables)
        gradients_discriminator = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)

        generator_optimizer.apply_gradients(zip(gradients_generator, generator.trainable_variables))
        discriminator_optimizer.apply_gradients(zip(gradients_discriminator, discriminator.trainable_variables))

    predictions = generator(seed, training=False)

predictions = generator(seed, training=False)

fig = plt.figure(figsize=(4, 5))

for i in range(predictions.shape[0]):
    plt.subplot(4, 5, i+1)
    image = predictions[i, :, :, 0] * 127.5 + 127.5
    plt.imshow(image, cmap='gray')
    plt.axis('off')
plt.show()

#ALL epochs
fig = plt.figure(figsize=(4, 5))

for i in range(predictions.shape[0]):
    plt.subplot(4, 5, i+1)
    image = predictions[i, :, :, 0] * 127.5 + 127.5
    plt.imshow(image, cmap='gray')
    plt.axis('off')
plt.show()

"""# VAE"""

import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()

train_images = np.expand_dims(train_images, -1).astype('float32')
test_images = np.expand_dims(test_images[:20], -1).astype('float32')

train_images = train_images/255.0
test_images = test_images/255.0

BUFFER_SIZE = 60000
BATCH_SIZE = 128
train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(1)

latent_space_dim = 16
def create_encoder():
    inputs = tf.keras.layers.Input(shape=(28,28,1))

    x = tf.keras.layers.Conv2D(32, (3,3), padding="same")(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)

    x = tf.keras.layers.Conv2D(64, (3,3), padding="same", strides=2)(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)

    x = tf.keras.layers.Conv2D(64, (3,3), padding="same", strides=2)(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)

    x = tf.keras.layers.Conv2D(64, (3,3), padding="same")(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)

    x = tf.keras.layers.Flatten()(x)

    mean = tf.keras.layers.Dense(units=latent_space_dim)(x)
    log_var = tf.keras.layers.Dense(units=latent_space_dim)(x)

    def sampling(mean_log_var):
        mean, log_var = mean_log_var
        epsilon = tf.random.normal(shape=tf.shape(mean))
        random_sample = mean + tf.math.exp(log_var/2) * epsilon
        return random_sample

    outputs = tf.keras.layers.Lambda(sampling)([mean, log_var])

    model = tf.keras.Model(inputs=inputs, outputs=[mean, log_var, outputs])
    return model

def create_decoder():
    inputs = tf.keras.layers.Input(shape=(latent_space_dim))
    x = tf.keras.layers.Dense(units=7*7*64)(inputs)
    x = tf.keras.layers.Reshape((7,7,64))(x)
    x = tf.keras.layers.Conv2DTranspose(64, (3, 3), padding="same")(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)

    x = tf.keras.layers.Conv2DTranspose(64, (3, 3), padding="same", strides=2)(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)

    x = tf.keras.layers.Conv2DTranspose(64, (3, 3), padding="same", strides=2)(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = tf.keras.layers.LeakyReLU()(x)

    x = tf.keras.layers.Conv2DTranspose(1, (3, 3), padding="same")(x)
    outputs = tf.keras.layers.LeakyReLU()(x )
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    return model

encoder_model = create_encoder()
decoder_model = create_decoder()
optimizer_enc = tf.keras.optimizers.Adam(learning_rate=5e-4)
optimizer_dec = tf.keras.optimizers.Adam(learning_rate=5e-4)

def vae_loss(y_true, y_pred, mean, log_var):
    reconstruction_loss = tf.math.reduce_mean(tf.math.reduce_sum(tf.keras.losses.binary_crossentropy(y_true, y_pred), axis=(1, 2)))
    kl_loss = -0.5 * (1 + log_var - tf.math.square(mean) - tf.math.exp(log_var))
    kl_loss = tf.math.reduce_mean(tf.math.reduce_sum(kl_loss, axis=1))
    return (reconstruction_loss + kl_loss)

EPOCHS=50
for epoch in range(EPOCHS):
    print(epoch)
    for image_batch in train_dataset:
        with tf.GradientTape() as enc_tape, tf.GradientTape() as dec_tape:
            mean, log_var, enc_outputs = encoder_model(image_batch)
            reconstruction = decoder_model(enc_outputs)
            total_loss = vae_loss(image_batch, reconstruction, mean, log_var)

        gradients_enc = enc_tape.gradient(total_loss, encoder_model.trainable_variables)
        gradients_dec = dec_tape.gradient(total_loss, decoder_model.trainable_variables)

        optimizer_enc.apply_gradients(zip(gradients_enc, encoder_model.trainable_variables))
        optimizer_dec.apply_gradients(zip(gradients_dec, decoder_model.trainable_variables))

mean, log_var, enc_outputs = encoder_model(test_images, training=False)
reconst = decoder_model(enc_outputs, training=False)

fig = plt.figure(figsize=(4, 4))

for i in range(20):
    ax = fig.add_subplot(5, 4, i+1)
    ax.axis('off')
    ax.imshow(reconst[i, :,:,0]*255.0, cmap = 'gray')

fig = plt.figure(figsize=(4, 4))

for i in range(20):
    ax = fig.add_subplot(5, 4, i+1)
    ax.axis('off')
    ax.imshow(test_images[i, :,:,0]*255, cmap = 'gray')

